{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "#%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from scipy.stats.contingency import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "from sklearn.metrics import classification_report,f1_score, roc_auc_score,roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instr</th>\n",
       "      <th>class</th>\n",
       "      <th>nb.repeat</th>\n",
       "      <th>attendance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>...</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   instr  class  nb.repeat  attendance  difficulty  Q1  Q2  Q3  Q4  Q5  ...  \\\n",
       "0      1      2          1           0           4   3   3   3   3   3  ...   \n",
       "1      1      2          1           1           3   3   3   3   3   3  ...   \n",
       "2      1      2          1           2           4   5   5   5   5   5  ...   \n",
       "3      1      2          1           1           3   3   3   3   3   3  ...   \n",
       "4      1      2          1           0           1   1   1   1   1   1  ...   \n",
       "\n",
       "   Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28  \n",
       "0    3    3    3    3    3    3    3    3    3    3  \n",
       "1    3    3    3    3    3    3    3    3    3    3  \n",
       "2    5    5    5    5    5    5    5    5    5    5  \n",
       "3    3    3    3    3    3    3    3    3    3    3  \n",
       "4    1    1    1    1    1    1    1    1    1    1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('turkiye_student_evaluation.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instr</th>\n",
       "      <th>class</th>\n",
       "      <th>nb.repeat</th>\n",
       "      <th>attendance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>...</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5815</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5816</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5817</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5818</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5819</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      instr  class  nb.repeat  attendance  difficulty  Q1  Q2  Q3  Q4  Q5  \\\n",
       "5815      3     13          1           0           1   1   1   1   1   1   \n",
       "5816      3     13          1           3           4   4   4   4   4   4   \n",
       "5817      3     13          1           0           4   5   5   5   5   5   \n",
       "5818      3     13          1           1           2   1   1   1   1   1   \n",
       "5819      3     13          1           1           2   1   1   1   1   1   \n",
       "\n",
       "      ...  Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28  \n",
       "5815  ...    1    1    1    1    1    1    1    1    1    1  \n",
       "5816  ...    5    5    5    5    4    5    5    5    5    5  \n",
       "5817  ...    5    5    5    5    5    5    5    5    5    5  \n",
       "5818  ...    1    1    1    1    1    1    1    1    1    1  \n",
       "5819  ...    1    1    1    1    1    1    1    1    1    1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instr         False\n",
       "class         False\n",
       "nb.repeat     False\n",
       "attendance    False\n",
       "difficulty    False\n",
       "Q1            False\n",
       "Q2            False\n",
       "Q3            False\n",
       "Q4            False\n",
       "Q5            False\n",
       "Q6            False\n",
       "Q7            False\n",
       "Q8            False\n",
       "Q9            False\n",
       "Q10           False\n",
       "Q11           False\n",
       "Q12           False\n",
       "Q13           False\n",
       "Q14           False\n",
       "Q15           False\n",
       "Q16           False\n",
       "Q17           False\n",
       "Q18           False\n",
       "Q19           False\n",
       "Q20           False\n",
       "Q21           False\n",
       "Q22           False\n",
       "Q23           False\n",
       "Q24           False\n",
       "Q25           False\n",
       "Q26           False\n",
       "Q27           False\n",
       "Q28           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instr', 'class', 'nb.repeat', 'attendance', 'difficulty', 'Q1', 'Q2',\n",
       "       'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13',\n",
       "       'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23',\n",
       "       'Q24', 'Q25', 'Q26', 'Q27', 'Q28'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instr</th>\n",
       "      <th>class</th>\n",
       "      <th>nb.repeat</th>\n",
       "      <th>attendance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>...</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.00000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>5820.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.485567</td>\n",
       "      <td>7.276289</td>\n",
       "      <td>1.214089</td>\n",
       "      <td>1.675601</td>\n",
       "      <td>2.783505</td>\n",
       "      <td>2.929897</td>\n",
       "      <td>3.073883</td>\n",
       "      <td>3.178694</td>\n",
       "      <td>3.082474</td>\n",
       "      <td>3.105842</td>\n",
       "      <td>...</td>\n",
       "      <td>3.261684</td>\n",
       "      <td>3.285395</td>\n",
       "      <td>3.307388</td>\n",
       "      <td>3.317526</td>\n",
       "      <td>3.20189</td>\n",
       "      <td>3.166838</td>\n",
       "      <td>3.312543</td>\n",
       "      <td>3.222165</td>\n",
       "      <td>3.154811</td>\n",
       "      <td>3.308076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.718473</td>\n",
       "      <td>3.688175</td>\n",
       "      <td>0.532376</td>\n",
       "      <td>1.474975</td>\n",
       "      <td>1.348987</td>\n",
       "      <td>1.341077</td>\n",
       "      <td>1.285251</td>\n",
       "      <td>1.253567</td>\n",
       "      <td>1.284594</td>\n",
       "      <td>1.278989</td>\n",
       "      <td>...</td>\n",
       "      <td>1.268442</td>\n",
       "      <td>1.276848</td>\n",
       "      <td>1.269974</td>\n",
       "      <td>1.268358</td>\n",
       "      <td>1.27259</td>\n",
       "      <td>1.275909</td>\n",
       "      <td>1.257286</td>\n",
       "      <td>1.270695</td>\n",
       "      <td>1.291872</td>\n",
       "      <td>1.278709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             instr        class    nb.repeat   attendance   difficulty  \\\n",
       "count  5820.000000  5820.000000  5820.000000  5820.000000  5820.000000   \n",
       "mean      2.485567     7.276289     1.214089     1.675601     2.783505   \n",
       "std       0.718473     3.688175     0.532376     1.474975     1.348987   \n",
       "min       1.000000     1.000000     1.000000     0.000000     1.000000   \n",
       "25%       2.000000     4.000000     1.000000     0.000000     1.000000   \n",
       "50%       3.000000     7.000000     1.000000     1.000000     3.000000   \n",
       "75%       3.000000    10.000000     1.000000     3.000000     4.000000   \n",
       "max       3.000000    13.000000     3.000000     4.000000     5.000000   \n",
       "\n",
       "                Q1           Q2           Q3           Q4           Q5  ...  \\\n",
       "count  5820.000000  5820.000000  5820.000000  5820.000000  5820.000000  ...   \n",
       "mean      2.929897     3.073883     3.178694     3.082474     3.105842  ...   \n",
       "std       1.341077     1.285251     1.253567     1.284594     1.278989  ...   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "25%       2.000000     2.000000     2.000000     2.000000     2.000000  ...   \n",
       "50%       3.000000     3.000000     3.000000     3.000000     3.000000  ...   \n",
       "75%       4.000000     4.000000     4.000000     4.000000     4.000000  ...   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000  ...   \n",
       "\n",
       "               Q19          Q20          Q21          Q22         Q23  \\\n",
       "count  5820.000000  5820.000000  5820.000000  5820.000000  5820.00000   \n",
       "mean      3.261684     3.285395     3.307388     3.317526     3.20189   \n",
       "std       1.268442     1.276848     1.269974     1.268358     1.27259   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.00000   \n",
       "25%       3.000000     3.000000     3.000000     3.000000     2.00000   \n",
       "50%       3.000000     3.000000     3.000000     3.000000     3.00000   \n",
       "75%       4.000000     4.000000     4.000000     4.000000     4.00000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.00000   \n",
       "\n",
       "               Q24          Q25          Q26          Q27          Q28  \n",
       "count  5820.000000  5820.000000  5820.000000  5820.000000  5820.000000  \n",
       "mean      3.166838     3.312543     3.222165     3.154811     3.308076  \n",
       "std       1.275909     1.257286     1.270695     1.291872     1.278709  \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "25%       2.000000     3.000000     2.000000     2.000000     3.000000  \n",
       "50%       3.000000     3.000000     3.000000     3.000000     3.000000  \n",
       "75%       4.000000     4.000000     4.000000     4.000000     4.000000  \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df.drop(['difficulty','instr','class','nb.repeat','attendance'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5815</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5816</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5817</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5820 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...  Q19  Q20  Q21  Q22  Q23  \\\n",
       "0      3   3   3   3   3   3   3   3   3    3  ...    3    3    3    3    3   \n",
       "1      3   3   3   3   3   3   3   3   3    3  ...    3    3    3    3    3   \n",
       "2      5   5   5   5   5   5   5   5   5    5  ...    5    5    5    5    5   \n",
       "3      3   3   3   3   3   3   3   3   3    3  ...    3    3    3    3    3   \n",
       "4      1   1   1   1   1   1   1   1   1    1  ...    1    1    1    1    1   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "5815   1   1   1   1   1   1   1   1   1    1  ...    1    1    1    1    1   \n",
       "5816   4   4   4   4   4   4   4   4   4    4  ...    5    5    5    5    4   \n",
       "5817   5   5   5   5   5   5   5   5   5    5  ...    5    5    5    5    5   \n",
       "5818   1   1   1   1   1   1   1   1   1    1  ...    1    1    1    1    1   \n",
       "5819   1   1   1   1   1   1   1   1   1    1  ...    1    1    1    1    1   \n",
       "\n",
       "      Q24  Q25  Q26  Q27  Q28  \n",
       "0       3    3    3    3    3  \n",
       "1       3    3    3    3    3  \n",
       "2       5    5    5    5    5  \n",
       "3       3    3    3    3    3  \n",
       "4       1    1    1    1    1  \n",
       "...   ...  ...  ...  ...  ...  \n",
       "5815    1    1    1    1    1  \n",
       "5816    5    5    5    5    5  \n",
       "5817    5    5    5    5    5  \n",
       "5818    1    1    1    1    1  \n",
       "5819    1    1    1    1    1  \n",
       "\n",
       "[5820 rows x 28 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>...</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5815</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5816</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5817</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5820 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  Q11  ...  Q19  Q20  Q21  Q22  Q23  \\\n",
       "0      3   3   3   3   3   3   3   3    3    3  ...    3    3    3    3    3   \n",
       "1      3   3   3   3   3   3   3   3    3    3  ...    3    3    3    3    3   \n",
       "2      5   5   5   5   5   5   5   5    5    5  ...    5    5    5    5    5   \n",
       "3      3   3   3   3   3   3   3   3    3    3  ...    3    3    3    3    3   \n",
       "4      1   1   1   1   1   1   1   1    1    1  ...    1    1    1    1    1   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "5815   1   1   1   1   1   1   1   1    1    1  ...    1    1    1    1    1   \n",
       "5816   4   4   4   4   4   4   4   4    4    4  ...    5    5    5    5    4   \n",
       "5817   5   5   5   5   5   5   5   5    5    5  ...    5    5    5    5    5   \n",
       "5818   1   1   1   1   1   1   1   1    1    1  ...    1    1    1    1    1   \n",
       "5819   1   1   1   1   1   1   1   1    1    1  ...    1    1    1    1    1   \n",
       "\n",
       "      Q24  Q25  Q26  Q27  Q28  \n",
       "0       3    3    3    3    3  \n",
       "1       3    3    3    3    3  \n",
       "2       5    5    5    5    5  \n",
       "3       3    3    3    3    3  \n",
       "4       1    1    1    1    1  \n",
       "...   ...  ...  ...  ...  ...  \n",
       "5815    1    1    1    1    1  \n",
       "5816    5    5    5    5    5  \n",
       "5817    5    5    5    5    5  \n",
       "5818    1    1    1    1    1  \n",
       "5819    1    1    1    1    1  \n",
       "\n",
       "[5820 rows x 27 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "sc=StandardScaler()\n",
    "X_scaled=sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "scores=cross_val_score(model,X_scaled,y,cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8762888665938731\n"
     ]
    }
   ],
   "source": [
    "print(scores.mean()) #accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8762888665938731"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()#precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.96071635e-02, -3.33488016e-02, -5.06309334e-02,\n",
       "        -7.22971172e-02, -3.52217137e-02, -1.57521337e-01,\n",
       "        -5.70017223e-02,  1.94156716e-02,  1.35003809e-01,\n",
       "         4.71102153e-02, -4.18857243e-02, -1.00494546e-02,\n",
       "         3.31971117e-03, -1.99351200e-01, -4.32435701e-02,\n",
       "         1.65454553e-01, -5.83203483e-02, -3.05251664e-02,\n",
       "         6.39974441e-02, -2.12630516e-01, -5.69771355e-03,\n",
       "         1.65927620e-01, -1.42448380e-01,  6.42394210e-02,\n",
       "        -2.85038629e-01, -4.69069712e-01, -6.99687436e+00],\n",
       "       [-3.52874593e-02,  2.94651509e-02, -9.99346110e-02,\n",
       "         1.98653299e-01,  3.16238673e-02,  2.51986191e-01,\n",
       "         5.59701134e-02,  8.97700228e-03, -2.52202638e-01,\n",
       "         2.88102648e-02,  7.26243722e-02, -1.73696259e-02,\n",
       "         1.99521841e-01,  3.98456980e-01, -1.55386788e-01,\n",
       "        -2.42074499e-01,  7.42373837e-02,  8.05377889e-02,\n",
       "        -2.37548605e-01,  3.90315453e-01, -1.58429774e-01,\n",
       "        -2.66968164e-01,  3.10465591e-02,  6.70554050e-02,\n",
       "         1.98595406e-01,  2.45890688e-01, -1.96352204e+00],\n",
       "       [-1.36513410e-01,  4.16924195e-02,  2.17453287e-01,\n",
       "        -2.41027244e-01,  3.20068283e-02, -1.29232170e-02,\n",
       "         2.24616193e-01, -7.42182987e-02,  7.58402619e-02,\n",
       "        -1.60215682e-01,  1.69856051e-01, -1.80072412e-01,\n",
       "         7.92451825e-02, -1.60550369e-02,  9.96959242e-02,\n",
       "         1.20059381e-01,  7.85889180e-03,  1.48659114e-02,\n",
       "         1.52194535e-01, -1.51223250e-01, -7.40437632e-02,\n",
       "        -4.69354512e-02, -2.63981397e-02, -1.25050556e-01,\n",
       "         2.62379145e-02,  2.00398578e-01, -4.87950080e-01],\n",
       "       [-1.03863010e-01, -3.62587132e-02,  7.97981606e-02,\n",
       "         7.74115805e-02,  8.74711673e-02,  2.62414178e-02,\n",
       "        -1.23922954e-01,  1.70162613e-02, -1.29990722e-01,\n",
       "         1.34706547e-01, -1.35390306e-01,  2.45539027e-02,\n",
       "         1.27868679e-01,  6.17394940e-03, -1.08378460e-01,\n",
       "         3.57346815e-02, -1.19288084e-01,  7.48384152e-02,\n",
       "        -2.34377530e-01,  1.93913789e-01,  9.27525685e-02,\n",
       "        -1.96489474e-01,  2.06469080e-01, -8.72319648e-02,\n",
       "         1.23235997e-01,  4.40169475e-02,  8.63829657e-01],\n",
       "       [ 4.38838990e-02,  8.70146227e-02, -7.20230796e-02,\n",
       "         3.69356609e-02, -2.66864521e-02, -7.46000778e-02,\n",
       "        -9.20068401e-03,  1.28938379e-02,  1.14781680e-02,\n",
       "        -2.50297185e-02,  3.69189622e-02,  1.16409230e-01,\n",
       "         3.24515009e-02, -8.65071493e-03, -2.07298072e-02,\n",
       "         3.67490004e-01, -2.70551617e-02, -3.45607220e-02,\n",
       "         2.42001633e-01, -3.86752564e-02,  1.89830559e-01,\n",
       "         1.10682650e-01, -1.25120866e-01,  3.80154899e-01,\n",
       "         6.90973751e-02,  2.47090106e-02,  9.53048758e+00]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train and test st\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_sc=sc.fit_transform(X_train)\n",
    "X_test_sc=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Logistic Regression to the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(penalty='l1', C=2.5)\n",
    "classifier.fit(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Prediciting the test set results\n",
    "y_pred = classifier.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[250   0   0   0   0]\n",
      " [  0  13 162   0   0]\n",
      " [  0   0 448  41   0]\n",
      " [  0   0  20 493   0]\n",
      " [  0   0   0   0 319]]\n"
     ]
    }
   ],
   "source": [
    "#Create a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8722794959908362\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of classifier\n",
    "print(classifier.score(X_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8722794959908362"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       250\n",
      "           2       1.00      0.07      0.14       175\n",
      "           3       0.71      0.92      0.80       489\n",
      "           4       0.92      0.96      0.94       513\n",
      "           5       1.00      1.00      1.00       319\n",
      "\n",
      "    accuracy                           0.87      1746\n",
      "   macro avg       0.93      0.79      0.78      1746\n",
      "weighted avg       0.90      0.87      0.84      1746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88034188 0.87842466 0.87972509 0.8814433  0.89003436 0.87435456\n",
      " 0.88123924 0.85714286 0.87607573 0.87607573]\n"
     ]
    }
   ],
   "source": [
    "#K fold corss validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(classifier, X,y, cv=10, scoring='accuracy')\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_dict={\n",
    "        'kernel':['linear','poly','rbf'],\n",
    "        'degree':[2,3],\n",
    "        'gamma':[0.01,0.1,1,10]\n",
    "        \n",
    "        \n",
    "        }\n",
    "clf=GridSearchCV(SVC(),param_dict)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.best_params_\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the best model\n",
    "svm=SVC(C=0.1,degree=2,gamma=0.1,kernel='linear')\n",
    "svm.fit(X_train,y_train)\n",
    "y_pred=svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#K fold corss validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(classifier, X,y, cv=10, scoring='accuracy')\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       250\n",
      "           2       1.00      1.00      1.00       175\n",
      "           3       1.00      1.00      1.00       489\n",
      "           4       1.00      1.00      1.00       513\n",
      "           5       1.00      1.00      1.00       319\n",
      "\n",
      "    accuracy                           1.00      1746\n",
      "   macro avg       1.00      1.00      1.00      1746\n",
      "weighted avg       1.00      1.00      1.00      1746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "accuracy_score(y_test,y_pred)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X=sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y,random_state=0,train_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9879725085910653"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=20,random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(y_test, y_train)\n",
    "ac = accuracy_score(y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 67,  45, 116, 111,  82],\n",
       "       [ 32,  33,  78,  90,  63],\n",
       "       [118,  67, 215, 229, 191],\n",
       "       [111,  73, 238, 252, 165],\n",
       "       [ 63,  46, 145, 174, 106]], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23127147766323025"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(DecisionTreeClassifier(),n_estimators=50,random_state=0)\n",
    "ada.fit(X_train,y_train)\n",
    "ada.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_test,y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       421\n",
      "           2       1.00      1.00      1.00       296\n",
      "           3       1.00      1.00      1.00       820\n",
      "           4       1.00      1.00      1.00       839\n",
      "           5       1.00      1.00      1.00       534\n",
      "\n",
      "    accuracy                           1.00      2910\n",
      "   macro avg       1.00      1.00      1.00      2910\n",
      "weighted avg       1.00      1.00      1.00      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_dict={\n",
    "        'kernel':['linear','poly','rbf'],\n",
    "        'degree':[2,3],\n",
    "        'gamma':[0.01,0.1,1,10]\n",
    "        \n",
    "        \n",
    "        }\n",
    "clf=GridSearchCV(SVC(),param_dict)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.best_params_\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the best model\n",
    "svm=SVC(C=0.1,degree=2,gamma=0.1,kernel='linear')\n",
    "svm.fit(X_train,y_train)\n",
    "y_pred=svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       421\n",
      "           2       1.00      1.00      1.00       296\n",
      "           3       1.00      1.00      1.00       820\n",
      "           4       1.00      1.00      1.00       839\n",
      "           5       1.00      1.00      1.00       534\n",
      "\n",
      "    accuracy                           1.00      2910\n",
      "   macro avg       1.00      1.00      1.00      2910\n",
      "weighted avg       1.00      1.00      1.00      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "accuracy_score(y_test,y_pred)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(y_test, y_train)\n",
    "ac = accuracy_score(y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 67,  45, 116, 111,  82],\n",
       "       [ 32,  33,  78,  90,  63],\n",
       "       [118,  67, 215, 229, 191],\n",
       "       [111,  73, 238, 252, 165],\n",
       "       [ 63,  46, 145, 174, 106]], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23127147766323025"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting K-NN to the Training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, weights='uniform', p = 2)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.91      0.93       212\n",
      "           2       0.77      0.77      0.77       148\n",
      "           3       0.83      0.88      0.86       411\n",
      "           4       0.83      0.89      0.86       416\n",
      "           5       0.96      0.81      0.88       268\n",
      "\n",
      "    accuracy                           0.86      1455\n",
      "   macro avg       0.87      0.85      0.86      1455\n",
      "weighted avg       0.87      0.86      0.86      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'finding optimal k')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(1,21):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    test_scores.append(cross_val_score(clf,X,y,cv=4).mean())\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1,21),test_scores)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('finding optimal k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8974359  0.91952055 0.89347079 0.90034364 0.88316151 0.84165232\n",
      " 0.84681583 0.8313253  0.87951807 0.86746988]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.876071380175801"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K fold corss validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(classifier, X,y, cv=10, scoring='accuracy')\n",
    "print(accuracies)\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_dict={\n",
    "        'kernel':['linear','poly','rbf'],\n",
    "        'degree':[2,3],\n",
    "        'gamma':[0.01,0.1,1,10]\n",
    "        \n",
    "        \n",
    "        }\n",
    "clf=GridSearchCV(SVC(),param_dict)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.best_params_\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the best model\n",
    "svm=SVC(C=0.1,degree=2,gamma=0.1,kernel='linear')\n",
    "svm.fit(X_train,y_train)\n",
    "y_pred=svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#K fold corss validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(classifier, X,y, cv=10, scoring='accuracy')\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       212\n",
      "           2       1.00      1.00      1.00       148\n",
      "           3       1.00      1.00      1.00       411\n",
      "           4       1.00      1.00      1.00       416\n",
      "           5       1.00      1.00      1.00       268\n",
      "\n",
      "    accuracy                           1.00      1455\n",
      "   macro avg       1.00      1.00      1.00      1455\n",
      "weighted avg       1.00      1.00      1.00      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "accuracy_score(y_test,y_pred)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'finding optimal k')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(1,21):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    test_scores.append(cross_val_score(clf,X,y,cv=4).mean())\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1,21),test_scores)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('finding optimal k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X=sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ac = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[209,   2,   1,   0,   0],\n",
       "       [  4, 141,   1,   2,   0],\n",
       "       [  0,   0, 411,   0,   0],\n",
       "       [  0,   1,   1, 414,   0],\n",
       "       [  0,   0,   0,   0, 268]], dtype=int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9917525773195877"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99487179 0.98972603 0.98969072 0.98797251 0.99312715 0.98795181\n",
      " 0.98795181 0.99483649 0.98623064 0.99483649]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0031937280379334817"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K fold cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(classifier, X,y, cv=10, scoring='accuracy')\n",
    "print(accuracies)\n",
    "accuracies.mean()\n",
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907195429191591"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9917525773195877"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.99      0.98       212\n",
      "           2       0.98      0.95      0.97       148\n",
      "           3       0.99      1.00      1.00       411\n",
      "           4       1.00      1.00      1.00       416\n",
      "           5       1.00      1.00      1.00       268\n",
      "\n",
      "    accuracy                           0.99      1455\n",
      "   macro avg       0.99      0.99      0.99      1455\n",
      "weighted avg       0.99      0.99      0.99      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_dict={\n",
    "        'kernel':['linear','poly','rbf'],\n",
    "        'degree':[2,3],\n",
    "        'gamma':[0.01,0.1,1,10]\n",
    "        \n",
    "        \n",
    "        }\n",
    "clf=GridSearchCV(SVC(),param_dict)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.best_params_\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the best model\n",
    "svm=SVC(C=0.1,degree=2,gamma=0.1,kernel='linear')\n",
    "svm.fit(X_train,y_train)\n",
    "y_pred=svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#K fold cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(classifier, X,y, cv=10, scoring='accuracy')\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       212\n",
      "           2       1.00      1.00      1.00       148\n",
      "           3       1.00      1.00      1.00       411\n",
      "           4       1.00      1.00      1.00       416\n",
      "           5       1.00      1.00      1.00       268\n",
      "\n",
      "    accuracy                           1.00      1455\n",
      "   macro avg       1.00      1.00      1.00      1455\n",
      "weighted avg       1.00      1.00      1.00      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "accuracy_score(y_test,y_pred)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#K fold cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(classifier, X,y, cv=10, scoring='accuracy')\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1457044673539519"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.25       212\n",
      "           2       0.00      0.00      0.00       148\n",
      "           3       0.00      0.00      0.00       411\n",
      "           4       0.00      0.00      0.00       416\n",
      "           5       0.00      0.00      0.00       268\n",
      "\n",
      "    accuracy                           0.15      1455\n",
      "   macro avg       0.03      0.20      0.05      1455\n",
      "weighted avg       0.02      0.15      0.04      1455\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "accuracy_score(y_test,y_pred)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_dict={\n",
    "        'kernel':['linear','poly','rbf'],\n",
    "        'degree':[2,3],\n",
    "        'gamma':[0.01,0.1,1,10]\n",
    "        \n",
    "        \n",
    "        }\n",
    "clf=GridSearchCV(SVC(),param_dict)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.best_params_\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the best model\n",
    "svm=SVC(C=0.1,degree=2,gamma=0.1,kernel='linear')\n",
    "svm.fit(X_train,y_train)\n",
    "y_pred=svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#K fold cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(classifier, X,y, cv=10, scoring='accuracy')\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       212\n",
      "           2       1.00      1.00      1.00       148\n",
      "           3       1.00      1.00      1.00       411\n",
      "           4       1.00      1.00      1.00       416\n",
      "           5       1.00      1.00      1.00       268\n",
      "\n",
      "    accuracy                           1.00      1455\n",
      "   macro avg       1.00      1.00      1.00      1455\n",
      "weighted avg       1.00      1.00      1.00      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "accuracy_score(y_test,y_pred)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the best model\n",
    "svm=SVC(C=0.1,degree=2,gamma=0.1,kernel='poly')\n",
    "svm.fit(X_train,y_train)\n",
    "y_pred=svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#K fold cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(classifier, X,y, cv=10, scoring='accuracy')\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       212\n",
      "           2       1.00      1.00      1.00       148\n",
      "           3       1.00      1.00      1.00       411\n",
      "           4       1.00      1.00      1.00       416\n",
      "           5       1.00      1.00      1.00       268\n",
      "\n",
      "    accuracy                           1.00      1455\n",
      "   macro avg       1.00      1.00      1.00      1455\n",
      "weighted avg       1.00      1.00      1.00      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "accuracy_score(y_test,y_pred)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
